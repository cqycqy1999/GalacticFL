batch_size: 32
learning_rate: 5e-5
num_epochs: 10
weight_decay: 0.01
gradient_accumulation_steps: 1
logging_steps: 100
evaluation_steps: 500
save_steps: 1000
max_grad_norm: 1.0
seed: 42
fp16: true
train_data_path: "data/train.json"
eval_data_path: "data/eval.json"
output_dir: "output/"
lora_rank: 16
lora_alpha: 32
lora_dropout: 0.1
model_name: "BloomZ-560M"